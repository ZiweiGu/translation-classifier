{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('quick-task-data/train.txt') as training_f:\n",
    "        train = training_f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['human'] = train[1::6]\n",
    "df['candidate'] = train[2::6]\n",
    "df['score'] = train[3::6]\n",
    "df['label'] = train[4::6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>candidate</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bahraini princess marries us soldier , astonis...</td>\n",
       "      <td>bahraini princess marries a u.s. soldier ; ast...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>the star-crossed marriage between bahraini pri...</td>\n",
       "      <td>u.s. television stations had once feted the ma...</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>meriam is a member of the gulf country bahrain...</td>\n",
       "      <td>meri gulf state of bahrain , the royal family ...</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>but the las vegas review-journal reported that...</td>\n",
       "      <td>however , according to the las vegas , comment...</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the pair met in 1999 when career military man ...</td>\n",
       "      <td>the two met in 1999 , when johnson was still a...</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>the new technique is simple , convenient , and...</td>\n",
       "      <td>new technologies with simple , convenient , fa...</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>upon the invitation of the china disease preve...</td>\n",
       "      <td>commissioned by the chinese center for disease...</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>spokesman for the ministry of foreign affairs ...</td>\n",
       "      <td>the mfa office spokesman told the house intern...</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>xinhua news agency report of december 3rd from...</td>\n",
       "      <td>beijing , december 3 ( xinhua ) -- the mfa off...</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>the spokesman said the speech in hong kong on ...</td>\n",
       "      <td>the spokesman claimed that china had expressed...</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 human  \\\n",
       "0    bahraini princess marries us soldier , astonis...   \n",
       "1    the star-crossed marriage between bahraini pri...   \n",
       "2    meriam is a member of the gulf country bahrain...   \n",
       "3    but the las vegas review-journal reported that...   \n",
       "4    the pair met in 1999 when career military man ...   \n",
       "..                                                 ...   \n",
       "579  the new technique is simple , convenient , and...   \n",
       "580  upon the invitation of the china disease preve...   \n",
       "581  spokesman for the ministry of foreign affairs ...   \n",
       "582  xinhua news agency report of december 3rd from...   \n",
       "583  the spokesman said the speech in hong kong on ...   \n",
       "\n",
       "                                             candidate   score label  \n",
       "0    bahraini princess marries a u.s. soldier ; ast...  0.3125     H  \n",
       "1    u.s. television stations had once feted the ma...  0.6531     H  \n",
       "2    meri gulf state of bahrain , the royal family ...  0.3784     M  \n",
       "3    however , according to the las vegas , comment...  0.3646     M  \n",
       "4    the two met in 1999 , when johnson was still a...  0.7778     H  \n",
       "..                                                 ...     ...   ...  \n",
       "579  new technologies with simple , convenient , fa...  0.3705     M  \n",
       "580  commissioned by the chinese center for disease...  0.6944     H  \n",
       "581  the mfa office spokesman told the house intern...  0.3267     M  \n",
       "582  beijing , december 3 ( xinhua ) -- the mfa off...  0.3858     M  \n",
       "583  the spokesman claimed that china had expressed...  0.6332     H  \n",
       "\n",
       "[584 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def walk_tree(node, depth):\n",
    "    '''\n",
    "    A helper function that calculates the max depth of a Spacy parse tree in a recursive way.\n",
    "    \n",
    "    '''\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return max(walk_tree(child, depth + 1) for child in node.children)\n",
    "    else:\n",
    "        return depth\n",
    "\n",
    "def extract_features(df):\n",
    "    rst = pd.DataFrame(columns=['bleu', 'similarity', 'tree_depth', 'func_density', 'pron_density'])\n",
    "    sw = stopwords.words('english')\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    for i, row in df.iterrows():\n",
    "        rst.at[i, 'bleu'] = row['score']\n",
    "        # calculate Jaccard similarity between human and candidate\n",
    "        x = {w for w in word_tokenize(row['human']) if not w in sw} \n",
    "        y = {w for w in word_tokenize(row['candidate']) if not w in sw} \n",
    "        rst.at[i, 'similarity'] = len(x.intersection(y))/ len(x.union(y))\n",
    "        # Extract linguistic features from candidate sentence\n",
    "        # normalized parse tree depth\n",
    "        doc = nlp(row['candidate'])\n",
    "        rst.at[i, 'tree_depth'] = [walk_tree(sent.root, 0) for sent in doc.sents][0]/ len(doc)\n",
    "        # density of function words and pronouns (based on POS tags)\n",
    "        count_f = 0\n",
    "        count_p = 0\n",
    "        for token in doc:\n",
    "            if token.pos_ in ['ADP', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'PART', 'SCONJ']:\n",
    "                count_f += 1\n",
    "            elif token.pos_ == 'PRON':\n",
    "                count_p += 1\n",
    "        rst.at[i, 'func_density'] = count_f/ len(doc)\n",
    "        rst.at[i, 'pron_density'] = count_p/ len(doc)\n",
    "    return rst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = extract_features(df)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>similarity</th>\n",
       "      <th>tree_depth</th>\n",
       "      <th>func_density</th>\n",
       "      <th>pron_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0972222</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bleu similarity tree_depth func_density pron_density\n",
       "0    0.3125   0.277778   0.214286     0.142857            0\n",
       "1    0.6531   0.689655   0.102041     0.204082            0\n",
       "2    0.3784   0.216216   0.189189     0.297297     0.027027\n",
       "3    0.3646   0.258065   0.181818     0.272727            0\n",
       "4    0.7778   0.692308   0.388889     0.222222            0\n",
       "..      ...        ...        ...          ...          ...\n",
       "579  0.3705   0.285714   0.152174     0.152174            0\n",
       "580  0.6944   0.555556  0.0972222     0.263889            0\n",
       "581  0.3267   0.307692   0.352941     0.117647            0\n",
       "582  0.3858   0.333333   0.189189     0.243243            0\n",
       "583  0.6332   0.533333   0.118644     0.305085            0\n",
       "\n",
       "[584 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>similarity</th>\n",
       "      <th>tree_depth</th>\n",
       "      <th>func_density</th>\n",
       "      <th>pron_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>584</td>\n",
       "      <td>584.0</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>441</td>\n",
       "      <td>224.0</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>10</td>\n",
       "      <td>34.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bleu  similarity  tree_depth  func_density  pron_density\n",
       "count      584       584.0  584.000000    584.000000         584.0\n",
       "unique     441       224.0  196.000000    180.000000          71.0\n",
       "top     0.5000         0.5    0.333333      0.333333           0.0\n",
       "freq        10        34.0   28.000000     39.000000         408.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7008547008547008\n",
      "F1 Score: 0.6995040561147868\n"
     ]
    }
   ],
   "source": [
    "# Create a svm classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Training accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on entire training set, then apply the model to test set\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "with open('quick-task-data/test.txt') as testing_f:\n",
    "        test = testing_f.read().split('\\n')\n",
    "test_df = pd.DataFrame()\n",
    "test_df['human'] = test[1::6]\n",
    "test_df['candidate'] = test[2::6]\n",
    "test_df['score'] = test[3::6]\n",
    "test_df['label'] = test[4::6]\n",
    "test_X = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_y = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7128717387338076\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using the average of F1 score for the human and machine classes\n",
    "print(metrics.f1_score(test_y, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'H', 'H', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'H', 'M', 'H',\n",
       "       'M', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M',\n",
       "       'H', 'H', 'M', 'H', 'M', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'M',\n",
       "       'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'H', 'H', 'H', 'H', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'H', 'H', 'M', 'H', 'H', 'H', 'M', 'M', 'M', 'H', 'H',\n",
       "       'M', 'M', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'H', 'H', 'M', 'H', 'M',\n",
       "       'H', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'H', 'H', 'M', 'H',\n",
       "       'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'H', 'M', 'H', 'H', 'H',\n",
       "       'H', 'H', 'H', 'H', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'H', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
